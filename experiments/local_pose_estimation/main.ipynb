{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from ssc import ssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_files = sorted(glob.glob(\"frames/frame_*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [cv2.imread(frame_file, cv2.IMREAD_COLOR) for frame_file in frame_files[:300]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0f3338b5d14f4db7db4682b1474db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9892bcdf10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(frames[0][:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1920\n",
    "h = 1080\n",
    "fx = 1184.51770\n",
    "fy = 1183.63810\n",
    "cx = 978.30778\n",
    "cy = 533.85598\n",
    "camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "fast = cv2.FastFeatureDetector_create(threshold=12)\n",
    "num_ret_points = 3000\n",
    "tolerance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kp_des(frame, fast, orb):\n",
    "    kp = fast.detect(frame, None)\n",
    "    kp = sorted(kp, key = lambda x:x.response, reverse=True)\n",
    "    kp = ssc(kp, num_ret_points, tolerance, frame.shape[1], frame.shape[0])\n",
    "    kp, des = orb.compute(frame, kp)\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "def match(bf, last_keyframe, current_frame, last_des, des, last_kp, kp, distance_threshold=30.0, draw=True):\n",
    "    matches = bf.match(last_des, des)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    # filter out matches with distance (descriptor appearance) greater than threshold\n",
    "    matches = [m for m in matches if m.distance < distance_threshold]\n",
    "    print(\"Found {} matches of current frame with last key frame\".format(len(matches)))\n",
    "    last_pts = np.array([last_kp[m.queryIdx].pt for m in matches]).reshape(1, -1, 2)\n",
    "    current_pts = np.array([kp[m.trainIdx].pt for m in matches]).reshape(1, -1, 2)\n",
    "    match_frame = np.zeros_like(current_frame)\n",
    "    if draw:\n",
    "        match_frame = cv2.drawMatches(last_keyframe, last_kp, current_frame, kp, matches[:250], None)\n",
    "    return matches, last_pts, current_pts, match_frame\n",
    "\n",
    "\n",
    "def to_twist(R, t):\n",
    "    \"\"\"Convert a 3x3 rotation matrix and translation vector (shape (3,))\n",
    "    into a 6D twist coordinate (shape (6,)).\"\"\"\n",
    "    r, _ = cv2.Rodrigues(R)\n",
    "    twist = np.zeros((6,))\n",
    "    twist[:3] = r.reshape(3,)\n",
    "    twist[3:] = t.reshape(3,)\n",
    "    return twist\n",
    "\n",
    "\n",
    "def from_twist(twist):\n",
    "    \"\"\"Convert a 6D twist coordinate (shape (6,)) into a 3x3 rotation matrix\n",
    "    and translation vector (shape (3,)).\"\"\"\n",
    "    r = twist[:3].reshape(3, 1)\n",
    "    t = twist[3:].reshape(3, 1)\n",
    "    R, _ = cv2.Rodrigues(r)\n",
    "    return R, t\n",
    "\n",
    "\n",
    "def get_frame(cap, mapx, mapy):\n",
    "    \"\"\"Reads and undistorts next frame from stream.\"\"\"\n",
    "    retc, frame = cap.read()\n",
    "    if not retc:\n",
    "        raise RuntimeError(\"Could not read the first camera frame.\")\n",
    "    frame = cv2.remap(frame, mapx, mapy, cv2.INTER_CUBIC)  # undistort frame\n",
    "    return frame\n",
    "\n",
    "\n",
    "def gray(frame):\n",
    "    \"\"\"Convert BGR frame to gray frame.\"\"\"\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return frame_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapPoints:\n",
    "    \"\"\"Map points\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "        idx (`numpy.ndarray`): Shape (-1,). Indices of map points ranging from \n",
    "            0 to N-1 for N map points.\n",
    "            \n",
    "        pts_3d (`numpy.ndarray`): Shape (-1, 3). The (X, Y, Z) coordinates of \n",
    "            each map point in the world reference frame.\n",
    "            \n",
    "        observing_keyframes (`list` of `list` of `int`): Contains one sublist \n",
    "            for each map point. Each sublist stores the indices of the key frames\n",
    "            which observe the map point. These key frame indices correspond to\n",
    "            the node index of the key frame in the pose graph.\n",
    "            \n",
    "        associated_kp_indices (`list` of `list` of `int`): Contains one sublist \n",
    "            for each map point. Each sublist stores the indices of the key points\n",
    "            within the observing keyframes from which the map point was triangulated.\n",
    "            E.g. given the observing key frames [0, 1, 2] for a map point, the \n",
    "            associated_kp_indices sublist [113, 20, 5] means that the map point \n",
    "            corresponds to key point 113 in key frame 0, key point 20 in key frame 1 \n",
    "            and key point 5 in key frame 2.        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Map points\"\"\"\n",
    "        self.idx = None\n",
    "        self.pts_3d = np.empty(shape=(0, 3), dtype=np.float64)\n",
    "        self.observing_keyframes = []\n",
    "        self.associated_kp_indices = []\n",
    "        \n",
    "        \n",
    "    def insert(self, new_map_points, associated_kp_indices, observing_kfs):\n",
    "        \"\"\"Add new map points into the exiting map.\"\"\"\n",
    "        if self.idx is not None:\n",
    "            self.idx = np.hstack((self.idx, np.arange(self.idx[-1]+1, self.idx[-1]+1+new_map_points.shape[0])))\n",
    "        else:\n",
    "            self.idx = np.arange(0, new_map_points.shape[0])\n",
    "        self.pts_3d = np.vstack((self.pts_3d, new_map_points))\n",
    "        for _ in range(new_map_points.shape[0]):\n",
    "            self.observing_keyframes.append(observing_kfs)\n",
    "        self.associated_kp_indices.extend(associated_kp_indices)\n",
    "    \n",
    "    \n",
    "    def get_by_observation(self, keyframe_idx):\n",
    "        \"\"\"Get all map points observed by a keyframe.\"\"\"\n",
    "        # get indices of all map points which are observed by the query keyframe\n",
    "        result_idx = np.array([i for i, mp in enumerate(self.observing_keyframes) if keyframe_idx in mp])\n",
    "        idx = self.idx[result_idx]\n",
    "        pts_3d = self.pts_3d[result_idx, :]\n",
    "        # get indices of keypoints associated to the map point in the query keyframe\n",
    "        pos_idx = [mp.index(keyframe_idx) for mp in self.observing_keyframes if keyframe_idx in mp]\n",
    "        associated_kp_indices = [self.associated_kp_indices[r][p] for r, p in zip(result_idx, pos_idx)]\n",
    "        return idx, pts_3d, associated_kp_indices\n",
    "    \n",
    "    \n",
    "    def get_keyframes_with_shared_map_points(self, keyframe_idx, min_shared=1):\n",
    "        \"\"\"Get all other keyframes which share at least `min_shared` map points with the query keyframe.\"\"\"\n",
    "        assert min_shared >= 1, \"min_shared must be 1 or larger.\"\n",
    "        tmp_pts = [p for mp in self.observing_keyframes for p in mp if keyframe_idx in mp]        \n",
    "        shared_kfs = set(tmp_pts)\n",
    "        shared_kfs.remove(keyframe_idx)  # do not return the query keyframe\n",
    "        # remove all frames with share less than min_shared points\n",
    "        num_shared = [tmp_pts.count(i) for i in shared_kfs]\n",
    "        shared_kfs = [s for s, n in zip(shared_kfs, num_shared) if n >= min_shared]\n",
    "        num_shared = [n for n in num_shared if n >= min_shared]\n",
    "        return shared_kfs, num_shared\n",
    "    \n",
    "    \n",
    "    def get_map_points_and_kps_for_matches(self, last_kf_index, current_kp, matches):\n",
    "        \"\"\"Returns map points and corresponding key points for current frame.\n",
    "\n",
    "        Given matches between a current frame and the last keyframe the function\n",
    "        finds which key point in the current frame correpsonds to which key point\n",
    "        in the last key frame and returns the map points correpsodning to these\n",
    "        key points. these can be used for solvePnP to get a first pose estimate of\n",
    "        the current frame.\n",
    "        \"\"\"\n",
    "        # get all map points observed in last KF\n",
    "        _, pts_3d, associated_kp_indices = self.get_by_observation(last_kf_index)  # get all map points observed by last KF\n",
    "\n",
    "        # get indices of map points which were found again in the current frame\n",
    "        kp_idxs = []\n",
    "        new_matches = []\n",
    "        for m in matches:\n",
    "            try:\n",
    "                kp_idx = associated_kp_indices.index(m.queryIdx)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            else:\n",
    "                kp_idxs.append(kp_idx)\n",
    "                new_matches.append(m)\n",
    "\n",
    "        print(\"{} of {} ({:3.3f} %) keypoints in last key frame have been found again in current frame\".format(len(new_matches), len(matches), len(new_matches)/len(matches)))\n",
    "\n",
    "        # get map points according to the indices\n",
    "        pts_3d = pts_3d[np.array(kp_idxs), :]\n",
    "\n",
    "        # get corresponding key points in the current frame\n",
    "        img_points = np.array([current_kp[m.trainIdx].pt for m in new_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        return pts_3d, img_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialization is not very robust and only works for some special cases, need to change to homography initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(fast, orb, camera_matrix, min_parallax=60.0):\n",
    "    \"\"\"Initialize two keyframes, the camera poses and a 3D point cloud.\n",
    "\n",
    "    Args:\n",
    "        min_parallax (`float`): Threshold for the median distance of all\n",
    "            keypoint matches between the first keyframe (firs frame) and the\n",
    "            second key frame. Is used to determine which frame is the second\n",
    "            keyframe. This is needed to ensure enough parallax to recover\n",
    "            the camera poses and 3D points.\n",
    "    \"\"\"\n",
    "    pose_graph = nx.Graph()  # stores keyframe poses and data (keypoints, ORB descriptors, etc.)\n",
    "    map_points = MapPoints() #np.empty(shape=(0, 3), dtype=np.float64)\n",
    "\n",
    "    # get first key frame\n",
    "    frame = frames[0]\n",
    "    kp, des = extract_kp_des(gray(frame), fast, orb)\n",
    "    pose_graph.add_node(0, frame=frame, kp=kp, des=des)\n",
    "\n",
    "    frame_idx_init = 0\n",
    "\n",
    "    for frame in frames[1:]:\n",
    "        \n",
    "        frame_idx_init += 1\n",
    "\n",
    "        # extract keypoints and match with first key frame\n",
    "        kp, des = extract_kp_des(gray(frame), fast, orb)\n",
    "        matches, last_pts, current_pts, match_frame = match(bf,\n",
    "            gray(pose_graph.nodes[0][\"frame\"]), gray(frame), pose_graph.nodes[0][\"des\"],\n",
    "            des, pose_graph.nodes[0][\"kp\"], kp, draw=False)\n",
    "\n",
    "        # determine median distance between all matched feature points\n",
    "        median_dist = np.median(np.linalg.norm(last_pts.reshape(-1, 2)-current_pts.reshape(-1, 2), axis=1))\n",
    "        print(median_dist)\n",
    "\n",
    "        # if distance exceeds threshold choose frame as second keyframe\n",
    "        if median_dist >= min_parallax:# and frame_idx_init >= 20:\n",
    "            pose_graph.add_node(1, frame=frame, kp=kp, des=des)\n",
    "            break\n",
    "\n",
    "    pose_graph.add_edge(0, 1, num_matches=len(matches))\n",
    "\n",
    "    # separately store the keypoints in matched order for tracking later\n",
    "    #pose_graph.nodes[0][\"kp_idx\"] = np.array([m.queryIdx for m in matches])\n",
    "    #pose_graph.nodes[1][\"kp_idx\"] = np.array([m.trainIdx for m in matches])\n",
    "\n",
    "    # compute relative camera pose for second frame\n",
    "    essential_mat, _ = cv2.findEssentialMat(last_pts.reshape(1, -1, 2), current_pts.reshape(1, -1, 2), camera_matrix, method=cv2.LMEDS)  # RANSAC fails here\n",
    "    num_inliers, R, t, mask = cv2.recoverPose(essential_mat, last_pts.reshape(1, -1, 2), current_pts.reshape(1, -1, 2), camera_matrix)\n",
    "    mask = mask.astype(np.bool).reshape(-1,)\n",
    "    print(num_inliers)\n",
    "\n",
    "    if num_inliers >= 0.25*current_pts.reshape(1, -1, 2).shape[1]:\n",
    "        print(\"init R\", R)\n",
    "        print(\"init t\", t)\n",
    "\n",
    "        # relative camera pose\n",
    "        R1 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]).astype(np.float64)\n",
    "        t1 = np.array([[0], [0], [0]]).astype(np.float64)\n",
    "        R2 = R.T\n",
    "        t2 = -np.matmul(R.T, t.reshape(3,)).reshape(3,1)\n",
    "\n",
    "        # insert pose (in twist coordinates) of KF0 and KF1 into keyframes dict\n",
    "        # poses are w.r.t. KF0 which is the base coordinate system of the entire map\n",
    "        pose_graph.nodes[0][\"pose\"] = to_twist(R1, t1)\n",
    "        pose_graph.nodes[1][\"pose\"] = to_twist(R2, t2)\n",
    "\n",
    "        # create projection matrices needed for triangulation of initial 3D point cloud\n",
    "        proj_matrix1 = np.hstack([R1.T, -R1.T.dot(t1)])\n",
    "        proj_matrix2 = np.hstack([R2.T, -R2.T.dot(t2)])\n",
    "        proj_matrix1 = camera_matrix.dot(proj_matrix1)\n",
    "        proj_matrix2 = camera_matrix.dot(proj_matrix2)\n",
    "\n",
    "        # triangulate initial 3D point cloud\n",
    "        pts_3d = cv2.triangulatePoints(proj_matrix1, proj_matrix2, last_pts.reshape(-1, 2).T, current_pts.reshape(-1, 2).T).T\n",
    "        pts_3d = cv2.convertPointsFromHomogeneous(pts_3d).reshape(-1, 3)\n",
    "\n",
    "        # filter outliers based on mask from recoverPose\n",
    "        #pts_3d = pts_3d[valid_map_points_mask, :].reshape(-1, 3)\n",
    "\n",
    "        # add triangulated points to map points\n",
    "        #map_points = np.vstack((map_points, pts_3d))  # map_points stores 3D points w.r.t. KF0\n",
    "        associated_kp_indices = [[m.queryIdx, m.trainIdx] for m in matches]\n",
    "        map_points.insert(pts_3d, associated_kp_indices, observing_kfs=[0, 1])  # triangulatedmap points between KF0 and KF1\n",
    "\n",
    "        # store indices of map points belonging to KF0 and KF1 in pose graph node\n",
    "        #pose_graph.nodes[0][\"associated_map_points\"] = np.arange(0, pts_3d.shape[0])\n",
    "        #pose_graph.nodes[1][\"associated_map_points\"] = np.arange(0, pts_3d.shape[0])\n",
    "\n",
    "        print(\"Initialization successful. Chose frames 0 and {} as key frames\".format(frame_idx_init))\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Could not recover intial camera pose based on selected keyframes. Insufficient parallax or number of feature points.\")\n",
    "\n",
    "    # TODO: perform full BA to optimize initial camera poses and map points [see. ORB_SLAM IV. 5)]\n",
    "\n",
    "    return pose_graph, map_points, frame_idx_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1038 matches of current frame with last key frame\n",
      "3.0\n",
      "Found 1118 matches of current frame with last key frame\n",
      "7.0\n",
      "Found 975 matches of current frame with last key frame\n",
      "10.04987562112089\n",
      "Found 1059 matches of current frame with last key frame\n",
      "13.038404810405298\n",
      "Found 976 matches of current frame with last key frame\n",
      "16.1245154965971\n",
      "Found 996 matches of current frame with last key frame\n",
      "20.024984394500787\n",
      "Found 958 matches of current frame with last key frame\n",
      "23.08679276123039\n",
      "Found 976 matches of current frame with last key frame\n",
      "26.076809620810597\n",
      "Found 910 matches of current frame with last key frame\n",
      "30.01666203960727\n",
      "Found 918 matches of current frame with last key frame\n",
      "33.06055050963308\n",
      "Found 931 matches of current frame with last key frame\n",
      "36.124783736376884\n",
      "Found 919 matches of current frame with last key frame\n",
      "39.20459156782532\n",
      "Found 919 matches of current frame with last key frame\n",
      "43.104524124504614\n",
      "Found 867 matches of current frame with last key frame\n",
      "46.17358552246078\n",
      "Found 888 matches of current frame with last key frame\n",
      "49.25444142409901\n",
      "Found 875 matches of current frame with last key frame\n",
      "53.08483775994799\n",
      "Found 866 matches of current frame with last key frame\n",
      "56.142675390472796\n",
      "Found 811 matches of current frame with last key frame\n",
      "59.21148537234985\n",
      "Found 881 matches of current frame with last key frame\n",
      "63.071388124885914\n",
      "876\n",
      "init R [[ 9.99998767e-01  1.46451064e-03 -5.67115895e-04]\n",
      " [-1.46446164e-03  9.99998924e-01  8.68049213e-05]\n",
      " [ 5.67242412e-04 -8.59742948e-05  9.99999835e-01]]\n",
      "init t [[-0.0567546 ]\n",
      " [-0.99785251]\n",
      " [-0.0326999 ]]\n",
      "Initialization successful. Chose frames 0 and 19 as key frames\n"
     ]
    }
   ],
   "source": [
    "pose_graph, map_points, frame_idx = initialize(fast, orb, camera_matrix, min_parallax=60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Last Keyframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_camera_pose(img_points, pts_3d, camera_matrix):\n",
    "    \"\"\"Estimates the camera world pose of a frame based on 2D-3D\n",
    "    corresponding points.\n",
    "\n",
    "    Args:\n",
    "        img_points (`numpy.ndarray`): A set of keypoints extracted from the\n",
    "            current frame. Shape (-1, 1, 2). These keypoints can also be tracked\n",
    "            from the previous frame.\n",
    "\n",
    "        pts_3d (`numpy.ndarray`): Triangulated 3D points corresponding to\n",
    "            the keypoints in img_points. Shape (-1, 1, 3). Note, that the order\n",
    "            of the points in this array needs to be consistent with the order of\n",
    "            keypoints in img_points.\n",
    "\n",
    "        camera_matrix (`numpy.ndarray`): Camera matrix of the camera which\n",
    "            was used to acquire frames.\n",
    "\n",
    "    Returns:\n",
    "        R (`numpy.ndarray`): Rotation matrix of the camera coordinate system\n",
    "            w.r.t. world coordinate system. Shape (3, 3).\n",
    "        t (`numpy.ndarray`): Translation (x, y, z) of the camera coordinate\n",
    "            system w.r.t. world coordinate system. Shape (3,).\n",
    "\n",
    "    Note:\n",
    "        This function assumes keypoints to be extracted from an undistorted\n",
    "        frame.\n",
    "    \"\"\"\n",
    "    success, rvec, tvec, inliers = cv2.solvePnPRansac(pts_3d.reshape(-1, 1, 3), img_points.reshape(-1, 1, 2), camera_matrix, None, reprojectionError=8, iterationsCount=100)\n",
    "    if not success:\n",
    "        raise RuntimeError(\"Could not compute the camera pose for the new frame with solvePnP.\")\n",
    "    print(\"solvePnP success\", success)\n",
    "    print(\"solvePnP inliers\", inliers.shape)\n",
    "    R = cv2.Rodrigues(rvec)[0].T\n",
    "    t = -np.matmul(cv2.Rodrigues(rvec)[0].T, tvec)\n",
    "    return R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_node_id = sorted(pose_graph.nodes)[-1]\n",
    "current_frame = frames[frame_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1208 matches of current frame with last key frame\n"
     ]
    }
   ],
   "source": [
    "# match current frame with last key frame\n",
    "current_kp, current_des = extract_kp_des(gray(current_frame), fast, orb)\n",
    "matches, last_pts, current_pts, match_frame = match(bf,\n",
    "        gray(pose_graph.nodes[prev_node_id][\"frame\"]),\n",
    "        gray(current_frame),\n",
    "        pose_graph.nodes[prev_node_id][\"des\"],\n",
    "        current_des, pose_graph.nodes[prev_node_id][\"kp\"],\n",
    "        current_kp, draw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583 of 1208 (0.483 %) keypoints in last key frame have been found again in current frame\n"
     ]
    }
   ],
   "source": [
    "pts_3d, img_points = map_points.get_map_points_and_kps_for_matches(prev_node_id, current_kp, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solvePnP success True\n",
      "solvePnP inliers (569, 1)\n",
      "[[ 9.99998651e-01 -1.63806149e-03  1.18871918e-04]\n",
      " [ 1.63797843e-03  9.99998417e-01  6.95540776e-04]\n",
      " [-1.20011068e-04 -6.95345129e-04  9.99999751e-01]] [[0.06882736]\n",
      " [1.04013118]\n",
      " [0.03505615]]\n"
     ]
    }
   ],
   "source": [
    "R_current, t_current = estimate_camera_pose(img_points, pts_3d, camera_matrix)\n",
    "current_pose = to_twist(R_current, t_current)\n",
    "print(R_current, t_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f210338c226b4f3a82e7569556156cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize matching\n",
    "match_frame = np.zeros_like(current_frame)\n",
    "match_frame = cv2.drawMatches(pose_graph.nodes[prev_node_id][\"frame\"], pose_graph.nodes[prev_node_id][\"kp\"], current_frame, current_kp, matches, None)\n",
    "\n",
    "w = current_frame.shape[1]\n",
    "\n",
    "for pt in img_points:    \n",
    "    match_frame = cv2.circle(match_frame, center=(int(w+pt[0, 0]), int(pt[0, 1])), radius=3, color=(0, 0, 0), thickness=-1)\n",
    "    \n",
    "f, ax = plt.subplots(1, figsize=(16,8))\n",
    "ax.imshow(match_frame[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Keyframe Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_indices = [67, 130, 195]\n",
    "kf_poses = [\n",
    "    np.array([-0.00380998, -0.00486231,  0.00420657,  0.21241029,  3.47167646,  0.13582189]),\n",
    "    np.array([ -8.78317890e-03,  -9.51736017e-03,   4.84237388e-03,   4.74222382e-01,  6.57213647e+00,   2.21628651e-01]),\n",
    "    np.array([ -1.52102216e-02,  -1.35126623e-02,   8.21807152e-03,   9.03560799e-01,   9.65644985e+00,   2.84139446e-01])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map points and pose graph for the status after several keyframes got inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 648 matches of current frame with last key frame\n",
      "R1, t1 (array([[ 9.99998767e-01, -1.46446164e-03,  5.67242412e-04],\n",
      "       [ 1.46451064e-03,  9.99998924e-01, -8.59742947e-05],\n",
      "       [-5.67115895e-04,  8.68049213e-05,  9.99999835e-01]]), array([[0.05531177],\n",
      "       [0.99793174],\n",
      "       [0.03275433]]))\n",
      "R2, t2 (array([[ 0.99997933, -0.00419727, -0.00487028],\n",
      "       [ 0.00421579,  0.99998389,  0.00379972],\n",
      "       [ 0.00485425, -0.00382017,  0.99998092]]), array([[0.21241029],\n",
      "       [3.47167646],\n",
      "       [0.13582189]]))\n",
      "pts_3d [[  10.26940804    6.8484795    18.64343648]\n",
      " [ -11.8136323     7.56454071   19.09363911]\n",
      " [  -8.49965223    8.86924865   19.12076673]\n",
      " ...\n",
      " [   6.42701332   -1.24758336   18.70044031]\n",
      " [ 130.43156103  -57.79092774 -178.20797092]\n",
      " [ -10.02106994    9.07392187   19.11675808]]\n",
      "Found 596 matches of current frame with last key frame\n",
      "R1, t1 (array([[ 0.99997933, -0.00419727, -0.00487028],\n",
      "       [ 0.00421579,  0.99998389,  0.00379972],\n",
      "       [ 0.00485425, -0.00382017,  0.99998092]]), array([[0.21241029],\n",
      "       [3.47167646],\n",
      "       [0.13582189]]))\n",
      "R2, t2 (array([[ 0.99994299, -0.00480042, -0.00953832],\n",
      "       [ 0.00488402,  0.9999497 ,  0.00875986],\n",
      "       [ 0.00949579, -0.00880594,  0.99991614]]), array([[0.47422238],\n",
      "       [6.57213647],\n",
      "       [0.22162865]]))\n",
      "pts_3d [[  4.14535307   5.41380712  18.73141742]\n",
      " [ 12.31948128   8.7038786   18.83448526]\n",
      " [-12.72244756   0.936843    18.74837795]\n",
      " ...\n",
      " [-12.21825377   0.09164153  19.1787107 ]\n",
      " [ -3.21933807   1.97943071  19.06750933]\n",
      " [ -5.09894554   1.47998357  18.86591909]]\n",
      "Found 603 matches of current frame with last key frame\n",
      "R1, t1 (array([[ 0.99994299, -0.00480042, -0.00953832],\n",
      "       [ 0.00488402,  0.9999497 ,  0.00875986],\n",
      "       [ 0.00949579, -0.00880594,  0.99991614]]), array([[0.47422238],\n",
      "       [6.57213647],\n",
      "       [0.22162865]]))\n",
      "R2, t2 (array([[ 0.99987494, -0.00811465, -0.01357407],\n",
      "       [ 0.00832017,  0.99985056,  0.01515348],\n",
      "       [ 0.01344908, -0.01526452,  0.99979304]]), array([[0.9035608 ],\n",
      "       [9.65644985],\n",
      "       [0.28413945]]))\n",
      "pts_3d [[ 13.65780064  10.64398035  19.01767079]\n",
      " [ -6.43066496   1.99850415  19.08823544]\n",
      " [  3.21458548   8.1175222   19.01171733]\n",
      " ...\n",
      " [ -5.92451786  12.40250271  19.19592201]\n",
      " [-11.80069261  11.58397107  19.1490397 ]\n",
      " [ -5.14327591   9.9606782   19.0743974 ]]\n"
     ]
    }
   ],
   "source": [
    "for frame_idx, kf_candidate_pose in zip(kf_indices, kf_poses):\n",
    "\n",
    "    kf_candidate_frame = frames[frame_idx]\n",
    "\n",
    "    kp_kf_match, des_kf_match = extract_kp_des(gray(kf_candidate_frame), fast, orb)\n",
    "    prev_node_id = sorted(pose_graph.nodes)[-1]\n",
    "    matches, last_pts, current_pts, match_frame = match(bf,\n",
    "        gray(pose_graph.nodes[prev_node_id][\"frame\"]),\n",
    "        gray(kf_candidate_frame),\n",
    "        pose_graph.nodes[prev_node_id][\"des\"],\n",
    "        des_kf_match, pose_graph.nodes[prev_node_id][\"kp\"],\n",
    "        kp_kf_match, 30.0, draw=True)\n",
    "\n",
    "    R1, t1 = from_twist(pose_graph.nodes[prev_node_id][\"pose\"])\n",
    "    R2, t2 = from_twist(kf_candidate_pose)\n",
    "\n",
    "    print(\"R1, t1\", (R1, t1))\n",
    "    print(\"R2, t2\", (R2, t2))\n",
    "\n",
    "    # create projection matrices needed for triangulation of 3D points\n",
    "    proj_matrix1 = np.hstack([R1.T, -R1.T.dot(t1)])\n",
    "    proj_matrix2 = np.hstack([R2.T, -R2.T.dot(t2)])\n",
    "    proj_matrix1 = camera_matrix.dot(proj_matrix1)\n",
    "    proj_matrix2 = camera_matrix.dot(proj_matrix2)\n",
    "\n",
    "    # triangulate new map points based on matches with previous key frame\n",
    "    pts_3d = cv2.triangulatePoints(proj_matrix1, proj_matrix2, last_pts.reshape(-1, 2).T, current_pts.reshape(-1, 2).T).T\n",
    "    pts_3d = cv2.convertPointsFromHomogeneous(pts_3d).reshape(-1, 3)\n",
    "\n",
    "    print(\"pts_3d\", pts_3d)\n",
    "    #map_points.append(pts_3d)\n",
    "\n",
    "    # insert new keyframe into pose graph\n",
    "    pose_graph.add_node(prev_node_id+1,\n",
    "        frame=kf_candidate_frame,\n",
    "        kp=kp_kf_match,\n",
    "        des=des_kf_match,\n",
    "        pose=kf_candidate_pose)\n",
    "    pose_graph.add_edge(prev_node_id, prev_node_id+1, num_matches=len(matches))\n",
    "\n",
    "    # add new map points\n",
    "    associated_kp_indices = [[m.queryIdx, m.trainIdx] for m in matches]\n",
    "    map_points.insert(pts_3d, associated_kp_indices, observing_kfs=[prev_node_id, prev_node_id+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1429 matches of current frame with last key frame\n",
      "417 of 1429 (0.292 %) keypoints in last key frame have been found again in current frame\n"
     ]
    }
   ],
   "source": [
    "# pose estimation for next frame\n",
    "current_frame = frames[196]\n",
    "current_kp, current_des = extract_kp_des(gray(current_frame), fast, orb)\n",
    "prev_node_id = sorted(pose_graph.nodes)[-1]\n",
    "\n",
    "matches, last_pts, current_pts, match_frame = match(bf,\n",
    "    gray(pose_graph.nodes[prev_node_id][\"frame\"]),\n",
    "    gray(current_frame),\n",
    "    pose_graph.nodes[prev_node_id][\"des\"],\n",
    "    current_des, pose_graph.nodes[prev_node_id][\"kp\"],\n",
    "    current_kp, 30.0, draw=True)\n",
    "\n",
    "#vis_current_frame = cv2.drawKeypoints(np.copy(current_frame), current_kp, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# get the map points and corresponding key points in last KF\n",
    "pts_3d, img_points = map_points.get_map_points_and_kps_for_matches(prev_node_id, current_kp, matches)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(pts_3d[:, 0], pts_3d[:, 1], pts_3d[:, 2])\n",
    "\n",
    "ax.scatter(img_points[:, 0, 0], img_points[:, 0, 1], color=\"red\")\n",
    "\n",
    "#ax.set_xlim([-20,20])\n",
    "#ax.set_ylim([-20,20])\n",
    "#ax.set_zlim([0,40])\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "ax.set_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solvePnP success True\n",
      "solvePnP inliers (393, 1)\n",
      "[[ 0.99987602 -0.00804579 -0.01353557]\n",
      " [ 0.00824276  0.99986003  0.01455953]\n",
      " [ 0.01341654 -0.01466929  0.99980238]] [[0.9093566 ]\n",
      " [9.71605292]\n",
      " [0.28180264]]\n"
     ]
    }
   ],
   "source": [
    "R_current, t_current = estimate_camera_pose(img_points, pts_3d, camera_matrix)\n",
    "current_pose = to_twist(R_current, t_current)\n",
    "print(R_current, t_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2464ce4614954b96984c8c0cab441286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize matching\n",
    "match_frame = np.zeros_like(current_frame)\n",
    "match_frame = cv2.drawMatches(pose_graph.nodes[prev_node_id][\"frame\"], pose_graph.nodes[prev_node_id][\"kp\"], current_frame, current_kp, matches[:200], None)\n",
    "\n",
    "w = current_frame.shape[1]\n",
    "\n",
    "for pt in img_points:    \n",
    "    match_frame = cv2.circle(match_frame, center=(int(w+pt[0, 0]), int(pt[0, 1])), radius=3, color=(0, 0, 0), thickness=-1)\n",
    "    \n",
    "f, ax = plt.subplots(1, figsize=(16,8))\n",
    "ax.imshow(match_frame[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Local Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute course pose estimate based on last KF\n",
    "# get all KFs which share map points observed in the current frame\n",
    "# get all neighbouring KFs of those KFs from step 1\n",
    "# get all map points from the KFs in step 1 and 2 (local map)\n",
    "# project local map into current frame\n",
    "# find matches between local map and key points in current frame\n",
    "# perform solvePnP with new additional matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_node_id = sorted(pose_graph.nodes)[-1]\n",
    "current_frame = frames[196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1429 matches of current frame with last key frame\n",
      "417 of 1429 (0.292 %) keypoints in last key frame have been found again in current frame\n",
      "solvePnP success True\n",
      "solvePnP inliers (393, 1)\n",
      "[[ 0.99987602 -0.00804579 -0.01353557]\n",
      " [ 0.00824276  0.99986003  0.01455953]\n",
      " [ 0.01341654 -0.01466929  0.99980238]] [[0.9093566 ]\n",
      " [9.71605292]\n",
      " [0.28180264]]\n"
     ]
    }
   ],
   "source": [
    "# compute course pose estimate based on last KF\n",
    "current_kp, current_des = extract_kp_des(gray(current_frame), fast, orb)\n",
    "matches, last_pts, current_pts, match_frame = match(bf,\n",
    "        gray(pose_graph.nodes[prev_node_id][\"frame\"]),\n",
    "        gray(current_frame),\n",
    "        pose_graph.nodes[prev_node_id][\"des\"],\n",
    "        current_des, pose_graph.nodes[prev_node_id][\"kp\"],\n",
    "        current_kp, draw=True)\n",
    "\n",
    "pts_3d, img_points = map_points.get_map_points_and_kps_for_matches(prev_node_id, current_kp, matches)\n",
    "\n",
    "R_current, t_current = estimate_camera_pose(img_points, pts_3d, camera_matrix)\n",
    "current_pose = to_twist(R_current, t_current)\n",
    "print(R_current, t_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_kfs: [3]\n",
      "neighbour_kfs: [2, 4]\n",
      "local_kfs: [2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# get all KFs which share map points observed in the current frame\n",
    "shared_kfs, _ = map_points.get_keyframes_with_shared_map_points(prev_node_id, min_shared=1)\n",
    "print(\"shared_kfs:\", shared_kfs)\n",
    "\n",
    "# get all neighbouring KFs of those KFs from step 1\n",
    "neighbour_kfs = [neighbor for skf in shared_kfs for neighbor in pose_graph.neighbors(skf)]\n",
    "print(\"neighbour_kfs:\", neighbour_kfs)\n",
    "\n",
    "# get all map points from the KFs in step 1 and 2 (local map)\n",
    "local_kfs = sorted(list(set(shared_kfs + neighbour_kfs)))\n",
    "print(\"local_kfs:\", local_kfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project local map into current frame\n",
    "projected_map_points = []\n",
    "\n",
    "for local_kf in local_kfs:\n",
    "    local_mps = map_points.get_by_observation(local_kf)\n",
    "    R, t = from_twist(pose_graph.nodes[local_kf][\"pose\"])\n",
    "    r_c, _ = cv2.Rodrigues(R.T)\n",
    "    t_c = -np.matmul(R.T, t.reshape(3,)).reshape(3, 1)\n",
    "    proj_pts, _ = cv2.projectPoints(local_mps[1].reshape(-1, 1, 3), r_c, t_c, camera_matrix, None)\n",
    "    projected_map_points.append(proj_pts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vis_current_frame = cv2.drawKeypoints(current_frame, current_kp, None, color=(255, 255, 255))  # keypoints of current frame\n",
    "vis_current_frame = cv2.drawKeypoints(vis_current_frame, cv2.KeyPoint_convert(proj_pts), None, color=(255, 0, 0))  # projected map from last KF\n",
    "f, ax = plt.subplots(1, figsize=(9,5))\n",
    "ax.imshow(vis_current_frame[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303ee0cb680e4f408a4a9ba37f048120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw frame 0\n",
    "#frame_z = pose_graph.nodes[4][\"frame\"]\n",
    "#kp_z, _ = extract_kp_des(gray(frame_z), fast, orb)\n",
    "#vis_current_frame = cv2.drawKeypoints(frame_z, kp_z, None, color=(255, 255, 255))  # keypoints of current frame\n",
    "vis_current_frame = cv2.drawKeypoints(current_frame, current_kp, None, color=(255, 255, 255))  # keypoints of current frame\n",
    "vis_current_frame = cv2.drawKeypoints(vis_current_frame, cv2.KeyPoint_convert(projected_map_points[0]), None, color=(255, 0, 0))  # projected map from last KF\n",
    "vis_current_frame = cv2.drawKeypoints(vis_current_frame, cv2.KeyPoint_convert(projected_map_points[1]), None, color=(0, 0, 255))  # projected map from last KF\n",
    "vis_current_frame = cv2.drawKeypoints(vis_current_frame, cv2.KeyPoint_convert(projected_map_points[2]), None, color=(0, 255, 0))  # projected map from last KF\n",
    "f, ax = plt.subplots(1, figsize=(9,5))\n",
    "ax.imshow(vis_current_frame[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find matches between local map and key points in current frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform solvePnP with new additional matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class KeyFrame:\n",
    "    def __init__(self, frame, kp, des):\n",
    "        self.frame = frame\n",
    "        self.kp = kp\n",
    "        self.des = des\n",
    "        self.pose = None\n",
    "        self.observed_map_points = None\n",
    "        \n",
    "    def get_observed_map_points(self, matches):\n",
    "        map_points = self.observed_map_points\n",
    "        kps = np.array(self.kp[m.queryIdx for m in matches])\n",
    "        \n",
    "        np.array([self.kp[m.queryIdx] for m in matches]).reshape(1, -1, 2)\n",
    "        return map_points, kps\n",
    "        \n",
    "    def get_neighbours(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def local_mapping():\n",
    "    \n",
    "    # get last KF and its neighbours in pose graph\n",
    "    # get all map points observed by these KFs\n",
    "    # estimate initial pose of current frame from previous KF (match -> PnP)\n",
    "    # project local map points () into current frame given the initial pose of this frame\n",
    "    # find further matches and corresponding keypoints in the KFs from step 2\n",
    "    # recompute PnP with all additional matches to get a more accurate pose estimate for current frame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "map_points.insert(np.random.randn(6, 3), [[102, 0], \n",
    " [39, 1],\n",
    " [1000, 2],\n",
    " [356, 3],\n",
    " [952, 4],\n",
    " [563, 5]], observing_kfs=[1, 2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_, idx1, idx2 = np.intersect1d(associated_kp_indices, np.array([m.queryIdx for m in matches]), assume_unique=True, return_indices=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for current_frame in frames[frame_idx+1:]:\n",
    "    # get initial pose estimate by matching keypoints with previous KF\n",
    "    current_kp, current_des = extract_kp_des(gray(current_frame), fast, orb)\n",
    "    prev_node_id = sorted(pose_graph.nodes)[-1]\n",
    "    matches, last_pts, current_pts, match_frame = match(bf,\n",
    "        gray(pose_graph.nodes[prev_node_id][\"frame\"]),\n",
    "        gray(current_frame),\n",
    "        pose_graph.nodes[prev_node_id][\"des\"],\n",
    "        current_des, pose_graph.nodes[prev_node_id][\"kp\"],\n",
    "        current_kp, num_matches, draw=False)\n",
    "\n",
    "    vis_current_frame = cv2.drawKeypoints(np.copy(current_frame), current_kp, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    # recover initial camera pose of current frame by solving PnP\n",
    "    img_points = current_pts\n",
    "    print(img_points.shape)\n",
    "    visible_map_points = pose_graph.nodes[prev_node_id][\"visible_map_points\"]  # may contain multiple disconnected index ranges\n",
    "    try:\n",
    "        pts_3d = np.vstack([map_points[vs, :] for vs in visible_map_points])\n",
    "    except ValueError:\n",
    "        raise ValueError (\"Last keyframe did not contain any visible map points.\")\n",
    "\n",
    "    print(\"pts3d\")\n",
    "    print(pts_3d)\n",
    "    print(pts_3d.shape)\n",
    "    print(pts_3d.dtype)\n",
    "    #print(\"current_pts before PnP\", img_points, \"len\", img_points.shape)\n",
    "    R_current, t_current = estimate_camera_pose(img_points, pts_3d, camera_matrix)\n",
    "    current_pose = to_twist(R_current, t_current)\n",
    "    print(R_current, t_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
